{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the distributed seismicity model\n",
    "\n",
    "Notes:\n",
    "* The catalogue used for the smoothing contains only earthquakes with magnitude larger than the 'cutoff_magnitude' parameter defined in the .ini file of the project"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%html\n",
    "<script>\n",
    "    var code_show=true; //true -> hide code at first\n",
    "\n",
    "    function code_toggle() {\n",
    "        $('div.prompt').hide(); // always hide prompt\n",
    "\n",
    "        if (code_show){\n",
    "            $('div.input').hide();\n",
    "        } else {\n",
    "            $('div.input').show();\n",
    "        }\n",
    "        code_show = !code_show\n",
    "    }\n",
    "    $( document ).ready(code_toggle);\n",
    "</script>\n",
    "<p style=\"font-size:60%;\">\n",
    "<a href=\"javascript:code_toggle()\">[Toggle Code]</a>\n",
    "<a target=\"_blank\" href=\"./../project/project_set_params_gui.ipynb#\">[Set params]</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import h5py\n",
    "import numpy\n",
    "import scipy\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "from decimal import *\n",
    "getcontext().prec = 4\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from oqmbt.oqt_project import OQtProject, OQtSource\n",
    "from oqmbt.tools.area import create_catalogue\n",
    "from oqmbt.tools.smooth import Smoothing\n",
    "from oqmbt.tools.mfd import get_evenlyDiscretizedMFD_from_truncatedGRMFD\n",
    "\n",
    "from openquake.hazardlib.source import PointSource, SimpleFaultSource\n",
    "from oqmbt.tools.geo import get_idx_points_inside_polygon\n",
    "from openquake.hazardlib.mfd.evenly_discretized import EvenlyDiscretizedMFD\n",
    "from openquake.hazardlib.mfd.truncated_gr import TruncatedGRMFD\n",
    "from openquake.hazardlib.geo.point import Point\n",
    "from openquake.hazardlib.geo.geodetic import azimuth, point_at\n",
    "\n",
    "from openquake.hmtk.seismicity.selector import CatalogueSelector\n",
    "\n",
    "from openquake.hazardlib.scalerel.wc1994 import WC1994\n",
    "from openquake.hazardlib.tom import PoissonTOM\n",
    "from openquake.hazardlib.pmf import PMF\n",
    "from openquake.hazardlib.geo.nodalplane import NodalPlane \n",
    "\n",
    "from oqmbt.notebooks.sources_distributed_s.utils import get_xy, get_polygon_from_simple_fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_pickle_filename = os.environ.get('OQMBT_PROJECT')\n",
    "oqtkp = OQtProject.load_from_file(project_pickle_filename)\n",
    "model_id = oqtkp.active_model_id\n",
    "model = oqtkp.models[model_id]\n",
    "print('Active model ID is:', model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_id = getattr(oqtkp,'active_source_id')[0]\n",
    "print('Area source ID:', src_id)\n",
    "src = model.sources[src_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the nodal plane distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# set the nodal plane distribution\n",
    "nodal_plane_dist_filename = os.path.join(oqtkp.directory, model.nodal_plane_dist_filename)\n",
    "fhdf5 = h5py.File(nodal_plane_dist_filename,'a')\n",
    "#\n",
    "# add the dataset for the current area source, if missing\n",
    "if (src_id in fhdf5.keys() and not ((fhdf5[src_id]['strike'][0] == 0) and \n",
    "                                    (fhdf5[src_id]['dip'][0] == 0) and\n",
    "                                    (fhdf5[src_id]['rake'][0] == 0))):\n",
    "    print('Using source-specific nodal plane distribution')\n",
    "    data = fhdf5[src_id][:]\n",
    "    tpll = []    \n",
    "    for idx in range(0, len(data)):\n",
    "        nplane = NodalPlane(data['strike'][idx],\n",
    "                            data['dip'][idx],\n",
    "                            data['rake'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(data['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), nplane))\n",
    "else:\n",
    "    print('Using default nodal plane distribution')\n",
    "    tpll = []\n",
    "    npd = model.default_nodal_plane_dist\n",
    "    for idx in range(0, len(npd['strike'])):\n",
    "        nplane = NodalPlane(npd['strike'][idx],\n",
    "                            npd['dip'][idx],\n",
    "                            npd['rake'][idx])\n",
    "        # tmp = float(data['wei'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(data['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), nplane))\n",
    "nodal_plane_distribution = PMF(tpll)    \n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hypocentral depth distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# read hypocentral depth file\n",
    "hypo_dist_filename = os.path.join(oqtkp.directory, model.hypo_dist_filename)\n",
    "fhdf5 = h5py.File(hypo_dist_filename,'a')\n",
    "#\n",
    "# check if the file contains information relative this source\n",
    "if (src_id in fhdf5.keys() and not ((fhdf5[src_id]['depth'][0] == 0) and \n",
    "                                    (fhdf5[src_id]['wei'][0] == 0))):\n",
    "    print('Using source-specific hypocentral depth distribution')\n",
    "    data = fhdf5[src_id][:]\n",
    "    tpll = []\n",
    "    for idx in range(0, len(data)):\n",
    "        #tmp = float(data['wei'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(data['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), data['depth'][idx]))\n",
    "else:\n",
    "    print('Using default hypocentral depth distribution')\n",
    "    tpll = []\n",
    "    hdd = model.default_hypo_dist\n",
    "    for idx in range(0, len(hdd['dep'])):\n",
    "        # tmp = float(hdd['wei'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(hdd['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), hdd['dep'][idx]))\n",
    "hypocenter_distribution = PMF(tpll)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_discretization = model.area_discretization \n",
    "buff = 2.0\n",
    "faults_lower_threshold_magnitude = model.faults_lower_threshold_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dilated polygon around the area source\n",
    "NOTE: We don't necessarily need to use the polygon of the area source. In a future version the polygon must be defined in the configuration file or computed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_polygon = src.polygon.dilate(100)\n",
    "polygon_mesh = new_polygon.discretize(area_discretization)\n",
    "print('Number of points: %d' % (len(polygon_mesh)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the earthquakes within the dilated polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the earthquakes of the catalogue within the dilated polygon \n",
    "pickle_filename = os.path.join(oqtkp.directory, oqtkp.models[model_id].declustered_catalogue_pickle_filename)\n",
    "fin = open(pickle_filename, 'rb') \n",
    "catalogue = pickle.load(fin)\n",
    "fin.close()\n",
    "print('The calogue contains %d earthquakes' % (len(catalogue.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we create the subcatalogue for the dilated polygon\n",
    "cutoff_magnitude = float(model.catalogue_cutoff_magnitude)\n",
    "fcatal = create_catalogue(model, catalogue, polygon=new_polygon)\n",
    "selector = CatalogueSelector(catalogue, create_copy=False)\n",
    "selector.within_magnitude_range(cutoff_magnitude, 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scaling factor based on completeness - For the time being we don't consider this.\n",
    "scalf = numpy.ones((len(fcatal.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_param = model.smoothing_param\n",
    "smooth = Smoothing(fcatal, polygon_mesh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = smooth.gaussian(50, 20)\n",
    "values = smooth.multiple_smoothing(smooth_param)\n",
    "print('Max of smoothing:', max(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot((111))\n",
    "#\n",
    "# plotting\n",
    "plt.scatter(smooth.mesh.lons, smooth.mesh.lats, c=values, vmin=0, vmax=max(values), marker='s', s=15)\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'r')\n",
    "plt.plot(fcatal.data['longitude'], fcatal.data['latitude'], 'og', mfc='white')\n",
    "#\n",
    "# find min and max longitude and latitude of the area source polygon\n",
    "lomin = min(src.polygon.lons) - buff\n",
    "lamin = min(src.polygon.lats) - buff\n",
    "lomax = max(src.polygon.lons) + buff\n",
    "lamax = max(src.polygon.lats) + buff\n",
    "#\n",
    "# fix axes limits\n",
    "ax.set_xlim([lomin, lomax])\n",
    "ax.set_ylim([lamin, lamax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm tmp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the nodes of the grid within the area source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxp = smooth.get_points_in_polygon(src.polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot((111))\n",
    "plt.scatter(smooth.mesh.lons[idxp], smooth.mesh.lats[idxp], vmin=0, vmax=0.4, c=values[idxp], marker='s', s=15)\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'r')\n",
    "if 'ids_faults_inside' in src.__dict__:\n",
    "    for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        tsrc = model.sources[key] \n",
    "        coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "        plt.plot(coord[:,0], coord[:,1], 'r')\n",
    "#\n",
    "# fix axes limits\n",
    "ax.set_xlim([lomin, lomax])\n",
    "ax.set_ylim([lamin, lamax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning seismicity to the source\n",
    "The redistribution of seismicity to the source is done for each cell using as a scaling factor the ratio of the value assigned to the node and the sum of the values of all the nodes within the area source. Note that the mfd assigned to the area source must be an EvenlyDiscretisedMFD instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 1. /sum(values[idxp])\n",
    "if isinstance(src.mfd, TruncatedGRMFD):\n",
    "    newmfd = get_evenlyDiscretizedMFD_from_truncatedGRMFD(src.mfd)\n",
    "    src.mfd = newmfd\n",
    "mfdpnts = numpy.array([src.mfd.occurrence_rates]*len(values))*scaling_factor\n",
    "#\n",
    "#\n",
    "xxx = numpy.tile(values, (mfdpnts.shape[1], 1)).T\n",
    "mfdpnts = mfdpnts * numpy.tile(values, (mfdpnts.shape[1], 1)).T\n",
    "#\n",
    "# \n",
    "mags = []\n",
    "for mag, _ in src.mfd.get_annual_occurrence_rates():\n",
    "    mags.append(mag)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting the MFDs of the point sources close to faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# find index of magnitudes above the threshold\n",
    "jjj = numpy.nonzero(numpy.array(mags) > faults_lower_threshold_magnitude)\n",
    "chng = numpy.zeros_like((values))\n",
    "#\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = plt.subplot(111)\n",
    "#\n",
    "#\n",
    "if hasattr(src, 'ids_faults_inside'):\n",
    "    for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        #\n",
    "        # Getting the fault source\n",
    "        tsrc = model.sources[key]\n",
    "        print('Source:', key)\n",
    "        \n",
    "        if 'mfd' in tsrc.__dict__ and tsrc.mfd is not None:\n",
    "        \n",
    "            lons, lats = get_xy(tsrc.trace) \n",
    "\n",
    "            # Create the polygon representing the surface projection of the fault\n",
    "            # surface\n",
    "            coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "            #\n",
    "            #\n",
    "            min_lon = numpy.min(lons)-buff\n",
    "            max_lon = numpy.max(lons)+buff\n",
    "            min_lat = numpy.min(lats)-buff\n",
    "            max_lat = numpy.max(lats)+buff\n",
    "\n",
    "            idxs = list(smooth.rtree.intersection((min_lon, min_lat, max_lon, max_lat)))\n",
    "\n",
    "            iii = get_idx_points_inside_polygon(smooth.mesh.lons[idxs], \n",
    "                                                smooth.mesh.lats[idxs],\n",
    "                                                list(coord[:,0]), \n",
    "                                                list(coord[:,1]), \n",
    "                                                idxs,\n",
    "                                                15000.0) \n",
    "            \n",
    "            for tidx in iii:\n",
    "                plt.plot(smooth.mesh.lons[tidx], smooth.mesh.lats[tidx], 'o')\n",
    "                mfdpnts[tidx, jjj] = 0.\n",
    "                chng[tidx] = 1.\n",
    "\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'g', lw=4)\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        tsrc = model.sources[key]\n",
    "        lons, lats = get_xy(tsrc.trace) \n",
    "        coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "        plt.plot(coord[:,0], coord[:,1], 'r')\n",
    "#\n",
    "# fix axes limits\n",
    "ax.set_xlim([lomin, lomax])\n",
    "ax.set_ylim([lamin, lamax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "m = Basemap(llcrnrlon=lomin,\n",
    "            llcrnrlat=lamin,\n",
    "            urcrnrlon=lomax,\n",
    "            urcrnrlat=lamax,\n",
    "            resolution='i',\n",
    "            projection='tmerc',\n",
    "            lon_0=106,\n",
    "            lat_0=28)\n",
    "\n",
    "#m.shadedrelief()\n",
    "x, y = m(smooth.mesh.lons, smooth.mesh.lats)\n",
    "rtes = numpy.sum(mfdpnts, axis=1)\n",
    "plt.scatter(x[idxp], y[idxp], s=9, marker='s', c=rtes[idxp], lw=0.)\n",
    "\n",
    "parallels = numpy.arange(lamin, lamax, 5.)\n",
    "#m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "meridians = numpy.arange(90, lomax, 5.)\n",
    "#m.drawmeridians(meridians,labels=[True,False,False,True])\n",
    "\n",
    "jjj = numpy.nonzero(chng > 0)\n",
    "plt.plot(x[jjj], y[jjj], 'x', lw=0.8, alpha=0.4, ms=8, markerfacecolor='None', markeredgecolor='purple')\n",
    "\n",
    "x, y = m(src.polygon.lons, src.polygon.lats)        \n",
    "plt.plot(x, y, 'g', lw=3)\n",
    "\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())):     \n",
    "    tsrc = model.sources[key]\n",
    "    coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "    x, y = m(coord[:,0], coord[:,1])\n",
    "    if 'mfd' in tsrc.__dict__ and tsrc.mfd is not None:\n",
    "        plt.plot(x, y, 'r', lw=3)\n",
    "    else:\n",
    "        plt.plot(x, y, '-', color='pink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the nrml sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmls = [] \n",
    "\n",
    "import importlib\n",
    "module = importlib.import_module('openquake.hazardlib.scalerel')\n",
    "my_class = getattr(module, model.msr)\n",
    "magnitude_scaling_relationship = my_class()\n",
    "\n",
    "rupture_mesh_spacing = model.fault_rupture_mesh_spacing\n",
    "rupture_aspect_ratio = model.fault_rupt_aspect_ratio\n",
    "temporal_occurrence_model = PoissonTOM(1.)\n",
    "\n",
    "for eee, iii in enumerate(idxp):\n",
    "    jjj = numpy.nonzero(mfdpnts[iii, :] > 0)\n",
    "    \n",
    "    if len(list(mfdpnts[iii, jjj][0])) > 0:\n",
    "        tmfd = EvenlyDiscretizedMFD(src.mfd.min_mag, src.mfd.bin_width, list(mfdpnts[iii, jjj][0]))\n",
    "\n",
    "        points = PointSource(\n",
    "            source_id='%d' % eee, \n",
    "            name='', \n",
    "            tectonic_region_type=src.tectonic_region_type,\n",
    "            mfd=tmfd, \n",
    "            rupture_mesh_spacing=rupture_mesh_spacing,\n",
    "            magnitude_scaling_relationship=magnitude_scaling_relationship, \n",
    "            rupture_aspect_ratio=rupture_aspect_ratio,\n",
    "            temporal_occurrence_model=temporal_occurrence_model,\n",
    "            upper_seismogenic_depth=model.upper_seismogenic_depth, \n",
    "            lower_seismogenic_depth=src.lower_seismogenic_depth,\n",
    "            location=Point(smooth.mesh.lons[iii], smooth.mesh.lats[iii]), \n",
    "            nodal_plane_distribution=nodal_plane_distribution, \n",
    "            hypocenter_distribution=hypocenter_distribution\n",
    "            )\n",
    "        nrmls.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openquake.hazardlib.sourcewriter import write_source_model\n",
    "# Write the nrml file\n",
    "model_dir = os.path.join(oqtkp.directory, 'nrml/%s' % (re.sub('\\s','_',model_id)))\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model_name = 'gridded_seismicity_source_%s.xml' % (src_id)\n",
    "out_model_name = os.path.join(model_dir, model_name)\n",
    "_ = write_source_model(out_model_name, nrmls, 'Model %s')\n",
    "print('Created %s ' % (out_model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
