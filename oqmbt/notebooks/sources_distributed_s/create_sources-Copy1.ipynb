{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the distributed seismicity model\n",
    "\n",
    "Notes:\n",
    "* The catalogue used for the smoothing contains only earthquakes with magnitude larger than the 'cutoff_magnitude' parameter defined in the .ini file of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    var code_show=true; //true -> hide code at first\n",
       "\n",
       "    function code_toggle() {\n",
       "        $('div.prompt').hide(); // always hide prompt\n",
       "\n",
       "        if (code_show){\n",
       "            $('div.input').hide();\n",
       "        } else {\n",
       "            $('div.input').show();\n",
       "        }\n",
       "        code_show = !code_show\n",
       "    }\n",
       "    $( document ).ready(code_toggle);\n",
       "</script>\n",
       "<p style=\"font-size:60%;\">\n",
       "<a href=\"javascript:code_toggle()\">[Toggle Code]</a>\n",
       "<a target=\"_blank\" href=\"./../project/project_set_params_gui.ipynb#\">[Set params]</a>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "    var code_show=true; //true -> hide code at first\n",
    "\n",
    "    function code_toggle() {\n",
    "        $('div.prompt').hide(); // always hide prompt\n",
    "\n",
    "        if (code_show){\n",
    "            $('div.input').hide();\n",
    "        } else {\n",
    "            $('div.input').show();\n",
    "        }\n",
    "        code_show = !code_show\n",
    "    }\n",
    "    $( document ).ready(code_toggle);\n",
    "</script>\n",
    "<p style=\"font-size:60%;\">\n",
    "<a href=\"javascript:code_toggle()\">[Toggle Code]</a>\n",
    "<a target=\"_blank\" href=\"./../project/project_set_params_gui.ipynb#\">[Set params]</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import h5py\n",
    "import numpy\n",
    "import scipy\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "from decimal import *\n",
    "getcontext().prec = 4\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from oqmbt.oqt_project import OQtProject, OQtSource\n",
    "from oqmbt.tools.area import create_catalogue\n",
    "from oqmbt.tools.smooth import Smoothing\n",
    "from oqmbt.tools.mfd import get_evenlyDiscretizedMFD_from_truncatedGRMFD\n",
    "\n",
    "from openquake.hazardlib.source import PointSource, SimpleFaultSource\n",
    "from oqmbt.tools.geo import get_idx_points_inside_polygon\n",
    "from openquake.hazardlib.mfd.evenly_discretized import EvenlyDiscretizedMFD\n",
    "from openquake.hazardlib.mfd.truncated_gr import TruncatedGRMFD\n",
    "from openquake.hazardlib.geo.point import Point\n",
    "from openquake.hazardlib.geo.geodetic import azimuth, point_at\n",
    "\n",
    "from openquake.hmtk.seismicity.selector import CatalogueSelector\n",
    "\n",
    "from openquake.hazardlib.scalerel.wc1994 import WC1994\n",
    "\n",
    "from openquake.hazardlib.tom import PoissonTOM\n",
    "from openquake.hazardlib.pmf import PMF\n",
    "from openquake.hazardlib.geo.nodalplane import NodalPlane \n",
    "\n",
    "from oqmbt.notebooks.sources_distributed_s.utils import get_xy, get_polygon_from_simple_fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = \"/Users/kjohnson/GEM/Regions/paisl18/project_10test/paisl.oqmbtp\"\n",
    "os.environ[\"OQMBT_PROJECT\"] = prj_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active model ID is: model10test\n"
     ]
    }
   ],
   "source": [
    "project_pickle_filename = os.environ.get('OQMBT_PROJECT')\n",
    "oqtkp = OQtProject.load_from_file(project_pickle_filename)\n",
    "model_id = oqtkp.active_model_id\n",
    "model = oqtkp.models[model_id]\n",
    "print('Active model ID is:', model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area source ID: 1\n"
     ]
    }
   ],
   "source": [
    "src_id = getattr(oqtkp,'active_source_id')[0]\n",
    "print('Area source ID:', src_id)\n",
    "src = model.sources[src_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the nodal plane distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using source-specific nodal plane distribution\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# set the nodal plane distribution\n",
    "nodal_plane_dist_filename = os.path.join(oqtkp.directory, model.nodal_plane_dist_filename)\n",
    "fhdf5 = h5py.File(nodal_plane_dist_filename,'a')\n",
    "#\n",
    "# add the dataset for the current area source, if missing\n",
    "if (src_id in fhdf5.keys() and not ((fhdf5[src_id]['strike'][0] == 0) and \n",
    "                                    (fhdf5[src_id]['dip'][0] == 0) and\n",
    "                                    (fhdf5[src_id]['rake'][0] == 0))):\n",
    "    print('Using source-specific nodal plane distribution')\n",
    "    data = fhdf5[src_id][:]\n",
    "    tpll = []    \n",
    "    for idx in range(0, len(data)):\n",
    "        nplane = NodalPlane(data['strike'][idx],\n",
    "                            data['dip'][idx],\n",
    "                            data['rake'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(data['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), nplane))\n",
    "else:\n",
    "    print('Using default nodal plane distribution')\n",
    "    tpll = []\n",
    "    npd = model.default_nodal_plane_dist\n",
    "    for idx in range(0, len(npd['strike'])):\n",
    "        nplane = NodalPlane(npd['strike'][idx],\n",
    "                            npd['dip'][idx],\n",
    "                            npd['rake'][idx])\n",
    "        # tmp = float(data['wei'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(data['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), nplane))\n",
    "nodal_plane_distribution = PMF(tpll)    \n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hypocentral depth distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using source-specific hypocentral depth distribution\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# read hypocentral depth file\n",
    "hypo_dist_filename = os.path.join(oqtkp.directory, model.hypo_dist_filename)\n",
    "fhdf5 = h5py.File(hypo_dist_filename,'a')\n",
    "#\n",
    "# check if the file contains information relative this source\n",
    "if (src_id in fhdf5.keys() and not ((fhdf5[src_id]['depth'][0] == 0) and \n",
    "                                    (fhdf5[src_id]['wei'][0] == 0))):\n",
    "    print('Using source-specific hypocentral depth distribution')\n",
    "    data = fhdf5[src_id][:]\n",
    "    tpll = []\n",
    "    for idx in range(0, len(data)):\n",
    "        #tmp = float(data['wei'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(data['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), data['depth'][idx]))\n",
    "else:\n",
    "    print('Using default hypocentral depth distribution')\n",
    "    tpll = []\n",
    "    hdd = model.default_hypo_dist\n",
    "    for idx in range(0, len(hdd['dep'])):\n",
    "        # tmp = float(hdd['wei'][idx])\n",
    "        tmp = Decimal('{:.2f}'.format(hdd['wei'][idx]))\n",
    "        tpll.append((Decimal(tmp), hdd['dep'][idx]))\n",
    "hypocenter_distribution = PMF(tpll)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.02, 5.0), (0.26, 15.0), (0.12, 25.0), (0.29, 35.0), (0.18, 45.0), (0.14, 55.0)]\n"
     ]
    }
   ],
   "source": [
    "print((hypocenter_distribution.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_discretization = model.area_discretization \n",
    "buff = 2.0\n",
    "faults_lower_threshold_magnitude = model.faults_lower_threshold_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dilated polygon around the area source\n",
    "NOTE: We don't necessarily need to use the polygon of the area source. In a future version the polygon must be defined in the configuration file or computed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 2854\n"
     ]
    }
   ],
   "source": [
    "new_polygon = src.polygon.dilate(100)\n",
    "polygon_mesh = new_polygon.discretize(area_discretization)\n",
    "print('Number of points: %d' % (len(polygon_mesh)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the earthquakes within the dilated polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calogue contains 3508 earthquakes\n"
     ]
    }
   ],
   "source": [
    "# First we get the earthquakes of the catalogue within the dilated polygon \n",
    "pickle_filename = os.path.join(oqtkp.directory, oqtkp.models[model_id].declustered_catalogue_pickle_filename)\n",
    "fin = open(pickle_filename, 'rb') \n",
    "catalogue = pickle.load(fin)\n",
    "fin.close()\n",
    "print('The calogue contains %d earthquakes' % (len(catalogue.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.356348002 -4.34025530494 0.000327410600452218 -605616.0094907793\n",
      "153.438308398 -4.37473114201 11781.944751208575 -610547.0084478441\n",
      "153.516470277 -4.41706313484 23028.522190511987 -616596.0714396511\n",
      "153.590076835 -4.46684167093 33632.827312172776 -623707.9106156178\n",
      "153.658414974 -4.52358501917 43493.485648106114 -631817.3016298282\n",
      "153.720822159 -4.58674395833 52515.57574808174 -640849.5750854176\n",
      "153.776692812 -4.65570705486 60611.51666843467 -650721.1898248455\n",
      "153.825484161 -4.72980654019 67701.91373371189 -661340.3879070212\n",
      "153.866721511 -4.80832473213 73716.35489433167 -672607.9305765426\n",
      "153.900002869 -4.89050093988 78594.14941459156 -684417.9138141937\n",
      "153.925002891 -4.97553878797 82285.0001002788 -696658.6611576251\n",
      "153.94147611 -5.06261389043 84749.59985550857 -709213.690398065\n",
      "153.949259411 -5.15088180327 85960.14308675182 -721962.7495042244\n",
      "153.948273725 -5.23948618056 85900.74239208006 -734782.915718184\n",
      "153.938524931 -5.32756705732 84567.74112607347 -747549.7502392977\n",
      "153.920103937 -5.41426918083 81969.91285251742 -760138.4993018814\n",
      "153.893185953 -5.49875031104 78128.53941878832 -772425.330808802\n",
      "153.85802894 -5.58018941041 73077.36042786989 -784288.5940654147\n",
      "153.814971254 -5.65779464396 66862.38825653278 -795610.0886308819\n",
      "153.76442849 -5.73081111109 59541.58446682066 -806276.3269367334\n",
      "153.706889569 -5.79852823298 51184.39546292012 -816179.7741867704\n",
      "153.64291207 -5.86028672131 41871.14752176992 -825220.0482174259\n",
      "153.573116881 -5.91548505793 31692.303820528257 -833305.0615264843\n",
      "153.498182191 -5.96358541902 20747.588731205593 -840352.0876245785\n",
      "153.418836887 -6.00411898212 9144.987371464189 -846288.7342674802\n",
      "153.33585343 -6.03669056063 -3000.368899252652 -851053.8070104171\n",
      "153.250040265 -6.06098251637 -15567.4177635182 -854598.0478916488\n",
      "151.943050319 -6.361178973 -207635.4679422141 -896992.1078667548\n",
      "150.96377005 -6.74833515272 -352981.0930751703 -950958.6898729339\n",
      "149.975686105 -7.13668310627 -500834.6944753137 -1003754.2660212739\n",
      "148.627111309 -7.88717481539 -706287.9079058965 -1106585.3342532853\n",
      "148.549499216 -7.92549836791 -718171.8642186855 -1111713.3518421664\n",
      "148.468545871 -7.95630959154 -730503.6011284566 -1115681.8828620068\n",
      "148.384992153 -7.97932617373 -743167.510227346 -1118452.0811431094\n",
      "148.299603246 -7.99433717369 -756044.4952036055 -1119996.6984222073\n",
      "148.213161494 -8.00120499823 -769013.1977519218 -1120300.4102518174\n",
      "148.1264591 -7.99986669159 -781951.25683339 -1119360.0041413144\n",
      "148.040290703 -7.99033452577 -794736.5837492405 -1117184.4262044653\n",
      "147.955445949 -7.97269588535 -807248.635053738 -1113794.6851569929\n",
      "147.872702097 -7.94711244783 -819369.6653331607 -1109223.6151225197\n",
      "147.792816764 -7.91381866815 -830985.9423206234 -1103515.5012804696\n",
      "147.716520866 -7.87311958325 -841988.9076836283 -1096725.5748419468\n",
      "147.64451183 -7.82538795928 -852276.2680784843 -1088919.3860912705\n",
      "147.577447148 -7.77106081108 -861753.0026634025 -1080172.0662139\n",
      "147.515938333 -7.71063532929 -870332.2751383553 -1070567.4902907948\n",
      "147.460545329 -7.64466425643 -877936.2404630146 -1060197.3551351773\n",
      "146.378299339 -6.21944150972 -1022622.9749116565 -838529.1732352256\n",
      "146.328071678 -6.14585389219 -1029136.1016934883 -827212.4447233985\n",
      "146.285419285 -6.06769835275 -1034479.7999703834 -815322.7862641066\n",
      "146.250756273 -5.98574025599 -1038604.604720938 -802979.8369638978\n",
      "146.224418091 -5.90078180938 -1041473.582054575 -790307.0447291313\n",
      "146.206658388 -5.8136541751 -1043062.552693021 -777430.352370239\n",
      "146.197646703 -5.72520931573 -1043360.1731753033 -764476.8893157253\n",
      "146.197466971 -5.63631165432 -1042367.8804464785 -751573.6843153893\n",
      "146.206116871 -5.54782962995 -1040099.7071144741 -738846.4129399662\n",
      "146.223508008 -5.46062723049 -1036581.9759292345 -726418.1919773235\n",
      "146.249466921 -5.37555558353 -1031852.882956457 -714408.4310564782\n",
      "146.283736903 -5.29344468561 -1025961.9795004115 -702931.7500673819\n",
      "146.325980616 -5.21509534785 -1018969.5631053721 -692096.9692449481\n",
      "146.375783456 -5.14127143414 -1010945.9879683143 -682006.1771985419\n",
      "146.432657662 -5.07269246472 -1001970.9048703767 -672753.8807311482\n",
      "146.496047103 -5.01002665492 -992132.4403262028 -664426.2390325293\n",
      "146.565332705 -4.95388445437 -981526.324106036 -657100.3837641027\n",
      "147.329636384 -4.39332390416 -865891.5747920189 -584492.123181441\n",
      "148.092990514 -3.83153363529 -751705.4119681023 -511243.03629645857\n",
      "148.855195294 -3.26886900131 -638995.1618403243 -437414.14403070847\n",
      "148.929455034 -3.21943564022 -628121.4296649259 -430957.2808501287\n",
      "149.008243798 -3.17757899587 -616668.240108193 -425594.29529208236\n",
      "149.090789625 -3.14370902714 -604745.6167923377 -421374.6571923824\n",
      "149.176283984 -3.11815744724 -592467.6239673792 -418337.1453882168\n",
      "149.263889643 -3.10117448921 -579951.3610624592 -416509.56541122554\n",
      "149.352748819 -3.09292646554 -567315.9437917618 -415908.5511364698\n",
      "149.441991533 -3.09349414615 -554681.4770450396 -416539.4497756481\n",
      "149.53074407 -3.10287197063 -542168.0245083707 -418396.2897005704\n",
      "149.618137487 -3.12096810249 -529894.5797934299 -421461.8307306202\n",
      "150.769173048 -3.41810144213 -367983.3690544786 -469109.90112656954\n",
      "150.846944011 -3.44187416671 -357017.50289452646 -472784.4564424441\n",
      "152.434966167 -4.00389950974 -131910.70294508565 -556896.6770542882\n",
      "152.445606499 -4.00772104184 -130392.87883996434 -557456.826732129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<openquake.hmtk.seismicity.catalogue.Catalogue at 0x10a4aae10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we create the subcatalogue for the dilated polygon\n",
    "cutoff_magnitude = float(model.catalogue_cutoff_magnitude)\n",
    "fcatal = create_catalogue(model, catalogue, polygon=new_polygon)\n",
    "selector = CatalogueSelector(catalogue, create_copy=False)\n",
    "selector.within_magnitude_range(cutoff_magnitude, 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scaling factor based on completeness - For the time being we don't consider this.\n",
    "scalf = numpy.ones((len(fcatal.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_param = model.smoothing_param"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def coord_generators(mesh):\n",
    "    for cnt, pnt in enumerate(mesh):\n",
    "        lon = pnt.longitude\n",
    "        lat = pnt.latitude\n",
    "        yield (cnt, (lon, lat, lon, lat), 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import rtree\n",
    "p = rtree.index.Property()\n",
    "p.get_overwrite=True\n",
    "r = rtree.index.Index(properties=p)\n",
    "ids = set()\n",
    "for cnt, pnt in enumerate(coord_generators(polygon_mesh)):\n",
    "    r.insert(id=pnt[0], coordinates=pnt[1])\n",
    "    # Check that the point IDs are unique\n",
    "    if pnt[0] not in ids:\n",
    "        #print(pnt)\n",
    "        ids.add(pnt[0])\n",
    "    else:\n",
    "        print(pnt[0])\n",
    "        raise ValueError('Index already used')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__func__', '__ge__', '__get__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RTreeError",
     "evalue": "Error in \"Index_Create\": Spatial Index Error: InvalidPageException: Unknown page id 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRTreeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-81d29c989518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcatal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolygon_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GEM/oq-mbtk/oqmbt/tools/smooth.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, catalogue, mesh, cellsize, completeness)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcellsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcellsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompleteness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompleteness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_spatial_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_create_spatial_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GEM/oq-mbtk/oqmbt/tools/smooth.py\u001b[0m in \u001b[0;36m_create_spatial_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# Create the spatial index for the grid mesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tmp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/rtree/index.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_idx_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndexHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/rtree/index.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/rtree/core.py\u001b[0m in \u001b[0;36mcheck_void\u001b[0;34m(result, func, cargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Error in \"%s\": %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError_Reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRTreeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRTreeError\u001b[0m: Error in \"Index_Create\": Spatial Index Error: InvalidPageException: Unknown page id 1"
     ]
    }
   ],
   "source": [
    "smooth = Smoothing(fcatal, polygon_mesh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smooth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1bb8c5d2145e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#values = smooth.gaussian(50, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Max of smoothing:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smooth' is not defined"
     ]
    }
   ],
   "source": [
    "#values = smooth.gaussian(50, 20)\n",
    "values = smooth.multiple_smoothing(smooth_param)\n",
    "print('Max of smoothing:', max(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot((111))\n",
    "#\n",
    "# plotting\n",
    "plt.scatter(smooth.mesh.lons, smooth.mesh.lats, c=values, vmin=0, vmax=max(values), marker='s', s=15)\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'r')\n",
    "plt.plot(fcatal.data['longitude'], fcatal.data['latitude'], 'og', mfc='white')\n",
    "#\n",
    "# find min and max longitude and latitude of the area source polygon\n",
    "lomin = min(src.polygon.lons) - buff\n",
    "lamin = min(src.polygon.lats) - buff\n",
    "lomax = max(src.polygon.lons) + buff\n",
    "lamax = max(src.polygon.lats) + buff\n",
    "#\n",
    "# fix axes limits\n",
    "ax.set_xlim([lomin, lomax])\n",
    "ax.set_ylim([lamin, lamax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm tmp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the nodes of the grid within the area source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxp = smooth.get_points_in_polygon(src.polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot((111))\n",
    "plt.scatter(smooth.mesh.lons[idxp], smooth.mesh.lats[idxp], vmin=0, vmax=0.4, c=values[idxp], marker='s', s=15)\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'r')\n",
    "if 'ids_faults_inside' in src.__dict__:\n",
    "    for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        tsrc = model.sources[key] \n",
    "        coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "        plt.plot(coord[:,0], coord[:,1], 'r')\n",
    "#\n",
    "# fix axes limits\n",
    "ax.set_xlim([lomin, lomax])\n",
    "ax.set_ylim([lamin, lamax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning seismicity to the source\n",
    "The redistribution of seismicity to the source is done for each cell using as a scaling factor the ratio of the value assigned to the node and the sum of the values of all the nodes within the area source. Note that the mfd assigned to the area source must be an EvenlyDiscretisedMFD instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 1. /sum(values[idxp])\n",
    "if isinstance(src.mfd, TruncatedGRMFD):\n",
    "    newmfd = get_evenlyDiscretizedMFD_from_truncatedGRMFD(src.mfd)\n",
    "    src.mfd = newmfd\n",
    "mfdpnts = numpy.array([src.mfd.occurrence_rates]*len(values))*scaling_factor\n",
    "#\n",
    "#\n",
    "xxx = numpy.tile(values, (mfdpnts.shape[1], 1)).T\n",
    "mfdpnts = mfdpnts * numpy.tile(values, (mfdpnts.shape[1], 1)).T\n",
    "#\n",
    "# \n",
    "mags = []\n",
    "for mag, _ in src.mfd.get_annual_occurrence_rates():\n",
    "    mags.append(mag)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting the MFDs of the point sources close to faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select a different smoothing buffer value \n",
    "smoothing_buffer = model.smoothing_buffer\n",
    "#\n",
    "#\n",
    "# find index of magnitudes above the threshold\n",
    "jjj = numpy.nonzero(numpy.array(mags) > faults_lower_threshold_magnitude)\n",
    "chng = numpy.zeros_like((values))\n",
    "#\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = plt.subplot(111)\n",
    "#\n",
    "#\n",
    "if hasattr(src, 'ids_faults_inside'):\n",
    "    for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        #\n",
    "        # Getting the fault source\n",
    "        tsrc = model.sources[key]\n",
    "        print('Source:', key)\n",
    "        \n",
    "        if 'mfd' in tsrc.__dict__ and tsrc.mfd is not None:\n",
    "        \n",
    "            lons, lats = get_xy(tsrc.trace) \n",
    "\n",
    "            # Create the polygon representing the surface projection of the fault\n",
    "            # surface\n",
    "            coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "            #\n",
    "            #\n",
    "            min_lon = numpy.min(lons)-buff\n",
    "            max_lon = numpy.max(lons)+buff\n",
    "            min_lat = numpy.min(lats)-buff\n",
    "            max_lat = numpy.max(lats)+buff\n",
    "\n",
    "            idxs = list(smooth.rtree.intersection((min_lon, min_lat, max_lon, max_lat)))\n",
    "\n",
    "            iii = get_idx_points_inside_polygon(smooth.mesh.lons[idxs], \n",
    "                                                smooth.mesh.lats[idxs],\n",
    "                                                list(coord[:,0]), \n",
    "                                                list(coord[:,1]), \n",
    "                                                idxs,\n",
    "                                                smoothing_buffer) \n",
    "            \n",
    "            for tidx in iii:\n",
    "                plt.plot(smooth.mesh.lons[tidx], smooth.mesh.lats[tidx], 'o')\n",
    "                mfdpnts[tidx, jjj] = 0.\n",
    "                chng[tidx] = 1.\n",
    "\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'g', lw=4)\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        tsrc = model.sources[key]\n",
    "        lons, lats = get_xy(tsrc.trace) \n",
    "        coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "        plt.plot(coord[:,0], coord[:,1], 'r')\n",
    "#\n",
    "# fix axes limits\n",
    "ax.set_xlim([lomin, lomax])\n",
    "ax.set_ylim([lamin, lamax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "m = Basemap(llcrnrlon=lomin,\n",
    "            llcrnrlat=lamin,\n",
    "            urcrnrlon=lomax,\n",
    "            urcrnrlat=lamax,\n",
    "            resolution='i',\n",
    "            projection='tmerc',\n",
    "            lon_0=106,\n",
    "            lat_0=28)\n",
    "\n",
    "#m.shadedrelief()\n",
    "x, y = m(smooth.mesh.lons, smooth.mesh.lats)\n",
    "rtes = numpy.sum(mfdpnts, axis=1)\n",
    "plt.scatter(x[idxp], y[idxp], s=9, marker='s', c=rtes[idxp], lw=0.)\n",
    "\n",
    "parallels = numpy.arange(lamin, lamax, 5.)\n",
    "#m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "meridians = numpy.arange(90, lomax, 5.)\n",
    "#m.drawmeridians(meridians,labels=[True,False,False,True])\n",
    "\n",
    "jjj = numpy.nonzero(chng > 0)\n",
    "plt.plot(x[jjj], y[jjj], 'x', lw=0.8, alpha=0.4, ms=8, markerfacecolor='None', markeredgecolor='purple')\n",
    "\n",
    "x, y = m(src.polygon.lons, src.polygon.lats)        \n",
    "plt.plot(x, y, 'g', lw=3)\n",
    "\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())):     \n",
    "    tsrc = model.sources[key]\n",
    "    coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "    x, y = m(coord[:,0], coord[:,1])\n",
    "    if 'mfd' in tsrc.__dict__ and tsrc.mfd is not None:\n",
    "        plt.plot(x, y, 'r', lw=3)\n",
    "    else:\n",
    "        plt.plot(x, y, '-', color='pink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the nrml sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id of the source is created as:\n",
    "# \"ds_src_id_iterator\". In this the point sources are related to the area_source with an unique Id by source\n",
    "\n",
    "nrmls = [] \n",
    "\n",
    "import importlib\n",
    "module = importlib.import_module('openquake.hazardlib.scalerel')\n",
    "my_class = getattr(module, model.msr)\n",
    "magnitude_scaling_relationship = my_class()\n",
    "\n",
    "rupture_mesh_spacing = model.fault_rupture_mesh_spacing\n",
    "rupture_aspect_ratio = model.fault_rupt_aspect_ratio\n",
    "temporal_occurrence_model = PoissonTOM(1.)\n",
    "\n",
    "for eee, iii in enumerate(idxp):\n",
    "    jjj = numpy.nonzero(mfdpnts[iii, :] > 0)\n",
    "    \n",
    "    if len(list(mfdpnts[iii, jjj][0])) > 0:\n",
    "        tmfd = EvenlyDiscretizedMFD(src.mfd.min_mag, src.mfd.bin_width, list(mfdpnts[iii, jjj][0]))\n",
    "\n",
    "        points = PointSource(\n",
    "            source_id='ds_%s_%d' % (src_id, eee), \n",
    "            name='', \n",
    "            tectonic_region_type=src.tectonic_region_type,\n",
    "            mfd=tmfd, \n",
    "            rupture_mesh_spacing=rupture_mesh_spacing,\n",
    "            magnitude_scaling_relationship=magnitude_scaling_relationship, \n",
    "            rupture_aspect_ratio=rupture_aspect_ratio,\n",
    "            temporal_occurrence_model=temporal_occurrence_model,\n",
    "            upper_seismogenic_depth=model.upper_seismogenic_depth, \n",
    "            lower_seismogenic_depth=src.lower_seismogenic_depth,\n",
    "            location=Point(smooth.mesh.lons[iii], smooth.mesh.lats[iii]), \n",
    "            nodal_plane_distribution=nodal_plane_distribution, \n",
    "            hypocenter_distribution=hypocenter_distribution\n",
    "            )\n",
    "        nrmls.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openquake.hazardlib.sourcewriter import write_source_model\n",
    "# Write the nrml file\n",
    "model_dir = os.path.join(oqtkp.directory, 'nrml/%s' % (re.sub('\\s','_',model_id)))\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model_name = 'gridded_seismicity_source_%s.xml' % (src_id)\n",
    "out_model_name = os.path.join(model_dir, model_name)\n",
    "_ = write_source_model(out_model_name, nrmls, 'Model %s')\n",
    "print('Created %s ' % (out_model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
