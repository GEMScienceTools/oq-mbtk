{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute hypocentral depth distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import h5py\n",
    "import numpy\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from oqmbt.oqt_project import OQtProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_pickle_filename = os.environ.get('OQMBT_PROJECT')\n",
    "oqtkp = OQtProject.load_from_file(project_pickle_filename)\n",
    "model_id = oqtkp.active_model_id\n",
    "model = oqtkp.models[model_id]\n",
    "# hdf5 files\n",
    "hypo_depths_hdf5_filename = os.path.join(oqtkp.directory, oqtkp.hypo_depths_hdf5_filename)\n",
    "# set source ID\n",
    "try:\n",
    "    area_source_ids_list = getattr(oqtkp,'active_source_id')\n",
    "except:\n",
    "    print('Active source ID not defined in the OQMBT project')\n",
    "    area_source_ids_list = ['10']\n",
    "print('Processing area source with ID:', area_source_ids_list)\n",
    "src_id = area_source_ids_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create catalogue for the analysed area source\n",
    "### Read the declustered catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = os.path.join(oqtkp.directory, oqtkp.models[model_id].declustered_catalogue_pickle_filename)\n",
    "fin = open(pickle_filename, 'rb') \n",
    "catalogue = pickle.load(fin)\n",
    "fin.close()\n",
    "print('The calogue contains %d earthquakes' % (len(catalogue.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create catalogue for the selected areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oqmbt.tools.area import create_catalogue\n",
    "fcatal = create_catalogue(model, catalogue, area_source_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the hypocentral depth histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = numpy.array(model.hypo_depth_bin_edges)\n",
    "\n",
    "depths = fcatal.data['depth']\n",
    "sdep = numpy.sort(depths)\n",
    "sdcs = numpy.cumsum(numpy.ones_like(sdep))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "histo, _ = numpy.histogram(depths, bins=bin_edges)\n",
    "histocum = numpy.cumsum(histo)\n",
    "    \n",
    "print(bin_edges[0:-1])\n",
    "print(numpy.diff(bin_edges))\n",
    "\n",
    "plt.bar(bin_edges[0:-1], \n",
    "        histo, \n",
    "        width=numpy.diff(bin_edges),\n",
    "        edgecolor='red', \n",
    "        facecolor='orange', \n",
    "        linewidth=3, \n",
    "        alpha=1.0,\n",
    "        label='incremental')\n",
    "\n",
    "plt.plot(sdep, sdcs, '--g', linewidth=3)\n",
    "\n",
    "plt.bar(bin_edges[0:-1], \n",
    "        histocum, \n",
    "        width=numpy.diff(bin_edges),\n",
    "        edgecolor='blue', \n",
    "        facecolor='white', \n",
    "        linewidth=3, \n",
    "        alpha=0.5,\n",
    "        label='cumulative')\n",
    "\n",
    "plt.xlabel(r'Hypocentral depth, [km]', fontsize=14)\n",
    "plt.ylabel(r'Earthquake count', fontsize=14)\n",
    "plt.grid(which='both', linestyle='--')\n",
    "plt.title('Area source %s' % area_source_ids_list[0])\n",
    "plt.xscale('log')\n",
    "plt.legend(loc=2)\n",
    "xlimits = plt.xlim([0, max(bin_edges)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "histo = histo.astype(float)\n",
    "histocum = histocum.astype(float)\n",
    "\n",
    "smm = sum(histo)\n",
    "histo /= smm\n",
    "histocum /= max(histocum)\n",
    "\n",
    "print(bin_edges[0:-1])\n",
    "\n",
    "plt.bar(bin_edges[0:-1], histo, \n",
    "        width=numpy.diff(bin_edges),\n",
    "        edgecolor='red', \n",
    "        facecolor='orange', \n",
    "        linewidth=3, \n",
    "        alpha=1.0,\n",
    "        label='incremental')\n",
    "\n",
    "plt.plot(sdep, sdcs/max(sdcs), '--g', linewidth=3)\n",
    "\n",
    "plt.bar(bin_edges[0:-1], \n",
    "        histocum, \n",
    "        width=numpy.diff(bin_edges),\n",
    "        edgecolor='blue', \n",
    "        facecolor='white', \n",
    "        linewidth=3, \n",
    "        alpha=0.5,\n",
    "        label='cumulative')\n",
    "\n",
    "plt.xlabel(r'Hypocentral depth, [km]', fontsize=14)\n",
    "plt.ylabel(r'Earthquake count', fontsize=14)\n",
    "plt.grid(which='both', linestyle='--')\n",
    "plt.title('Area source %s' % area_source_ids_list[0])\n",
    "plt.xscale('log')\n",
    "plt.legend(loc=1)\n",
    "xlimits = plt.xlim([0, max(bin_edges)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5bf1e7e98a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdecimal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypo_depths_hdf5_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcsv_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:s}-{:s}-{:s}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "from decimal import *\n",
    "\n",
    "aa = re.sub('\\.hdf5', '', os.path.basename(hypo_depths_hdf5_filename))\n",
    "csv_filename = '{:s}-{:s}-{:s}.csv'.format(aa, model_id, src_id)\n",
    "print(csv_filename)\n",
    "#\n",
    "#\n",
    "path = os.path.join(oqtkp.directory, 'hypo_depths')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print('Creating folder: {:s}'.format(path))\n",
    "else:\n",
    "    print('Folder {:s} exists'.format(path))\n",
    "#\n",
    "#\n",
    "dps = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "print(dps)\n",
    "wei = numpy.around(histo, 2)\n",
    "wei /= sum(wei)\n",
    "wei = numpy.around(wei,2)\n",
    "#print(wei)\n",
    "\n",
    "x_sum = sum(wei[0:-1])\n",
    "x_diff = 1.0-x_sum\n",
    "if (wei[-1]-x_diff)<0.01:\n",
    "    wei[-1] = x_diff\n",
    "else:\n",
    "    raise SystemExit('Weight correction failed! Check original weight assignments')\n",
    "#print(wei)\n",
    "#\n",
    "# Writing csv file\n",
    "outfile = os.path.join(path, csv_filename)\n",
    "print('Writing {:s}'.format(outfile))\n",
    "fou = open(outfile, 'w')\n",
    "fou.write('depth,weight\\n')\n",
    "for dep, wgh in zip(dps, wei):\n",
    "    if wgh > 1e-10:\n",
    "        fou.write('{:.2f},{:.2f}\\n'.format(dep, wgh))\n",
    "fou.close()\n",
    "jjj = numpy.nonzero(wei > 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing', hypo_depths_hdf5_filename)\n",
    "#\n",
    "# open the hdf5 file\n",
    "fhdf5 = h5py.File(hypo_depths_hdf5_filename,'a')\n",
    "#\n",
    "# Update/create model group\n",
    "if model_id in fhdf5.keys():\n",
    "    print('Group exists. Set group %s' % (model_id))\n",
    "    grp = fhdf5[model_id]\n",
    "else:\n",
    "    print('Create group: %s' % (model_id))\n",
    "    grp = fhdf5.create_group(model_id)\n",
    "#\n",
    "# update/create source group\n",
    "if src_id in fhdf5[model_id].keys():\n",
    "    print('Group exists. Set group %s' % (src_id))\n",
    "    grpsrc = fhdf5[model_id][src_id]\n",
    "else:\n",
    "    print('Create group: %s' % (src_id))\n",
    "    grpsrc = fhdf5[model_id].create_group(src_id)\n",
    "#\n",
    "# update/create datasets\n",
    "dset_ids = ['b_edges', 'hist', 'hist_cum', 'depth', 'weight']\n",
    "for dset_id in dset_ids:\n",
    "    if dset_id in grpsrc:\n",
    "        del grpsrc[dset_id]\n",
    "dataset = grpsrc.create_dataset(dset_ids[0], data=bin_edges)\n",
    "dataset = grpsrc.create_dataset(dset_ids[1], data=histo)\n",
    "dataset = grpsrc.create_dataset(dset_ids[2], data=histocum)\n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# open the hdf5 containing the hypocentral depth information\n",
    "hypo_dist_filename = os.path.join(oqtkp.directory, model.hypo_dist_filename)\n",
    "fhdf5 = h5py.File(hypo_dist_filename,'a')\n",
    "#\n",
    "#\n",
    "if src_id in fhdf5:\n",
    "    del fhdf5[src_id]\n",
    "#\n",
    "# updating the dataset for the current area source\n",
    "x = numpy.zeros(len(jjj[0]), dtype=[('depth','f4'),('wei', 'f4')])\n",
    "x['wei'] = wei[jjj]\n",
    "x['depth'] = dps[jjj] \n",
    "\n",
    "dset = fhdf5.create_dataset(src_id, data=x)\n",
    "fhdf5.close()\n",
    "\n",
    "print('{:s} updated - src {:s}'.format(hypo_dist_filename, src_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
