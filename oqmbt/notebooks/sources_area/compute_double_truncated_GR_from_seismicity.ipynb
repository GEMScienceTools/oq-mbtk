{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute double truncated GR from seismicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import h5py\n",
    "import numpy\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from openquake.hmtk.seismicity.occurrence.weichert import Weichert\n",
    "from openquake.hmtk.seismicity.occurrence.utils import get_completeness_counts\n",
    "from openquake.hmtk.plotting.seismicity.occurrence.recurrence_plot import plot_trunc_gr_model\n",
    "\n",
    "from oqmbt.oqt_project import OQtProject\n",
    "from oqmbt.tools.area import create_catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model with ID: model01\n",
      "Processing area source with ID: ['02']\n"
     ]
    }
   ],
   "source": [
    "project_pickle_filename = os.environ.get('OQMBT_PROJECT')\n",
    "oqtkp = OQtProject.load_from_file(project_pickle_filename)\n",
    "model_id = oqtkp.active_model_id\n",
    "model = oqtkp.models[model_id]\n",
    "#\n",
    "# hdf5 files\n",
    "compl_hdf5_filename = os.path.join(oqtkp.directory, oqtkp.compl_hdf5_filename)\n",
    "eqk_rates_hdf5_filename = os.path.join(oqtkp.directory, oqtkp.eqk_rates_hdf5_filename)\n",
    "#\n",
    "# set source ID\n",
    "try:\n",
    "    area_source_ids_list = getattr(oqtkp,'active_source_id')\n",
    "except:\n",
    "    print ('Active source ID not defined in the OQMBT project')\n",
    "    area_source_ids_list = ['02']\n",
    "#\n",
    "# info \n",
    "print ('Processing model with ID:', model_id)\n",
    "print ('Processing area source with ID:', area_source_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Width of bins used to discretise the MFDs\n",
    "binwidth = float(model.mfd_binwidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of GR parameters assigned to area sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+\n",
      "| ID | a_gr | b_gr |\n",
      "+----+------+------+\n",
      "| 02 |      |      |\n",
      "| 03 |      |      |\n",
      "+----+------+------+\n"
     ]
    }
   ],
   "source": [
    "# Set table\n",
    "p = PrettyTable([\"ID\",\"a_gr\", \"b_gr\"])\n",
    "p.align[\"Source ID\"] = 'l'\n",
    "p.align[\"a_gr\"] = 'r'\n",
    "p.align[\"b_gr\"] = 'r'\n",
    "#\n",
    "for key in sorted(model.sources):\n",
    "    src = model.sources[key]\n",
    "    if src.source_type == 'AreaSource':\n",
    "        alab = ''\n",
    "        blab = ''\n",
    "        if 'a_gr' in src.__dict__:\n",
    "            alab = '%8.5f' % (src.a_gr)\n",
    "        if 'b_gr' in src.__dict__:\n",
    "            blab = '%6.3f' % (src.b_gr)    \n",
    "        p.add_row([key, alab, blab])\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model01_catalogue.pkl\n",
      "The calogue contains 465 earthquakes\n"
     ]
    }
   ],
   "source": [
    "print (oqtkp.models[model_id].declustered_catalogue_pickle_filename)\n",
    "pickle_filename = os.path.join(oqtkp.directory, oqtkp.models[model_id].declustered_catalogue_pickle_filename)\n",
    "fin = open(pickle_filename, 'rb') \n",
    "catalogue = pickle.load(fin)\n",
    "fin.close()\n",
    "print ('The calogue contains %d earthquakes' % (len(catalogue.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create catalogue for the selected areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging eqks for source: 02 # eqks: 140\n",
      "Total number of earthquakes selected 140\n"
     ]
    }
   ],
   "source": [
    "fcatal = create_catalogue(model, catalogue, area_source_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum magnitude considered for the model is:  3.5\n",
      "Maximum observed magnitude is:  7.37\n"
     ]
    }
   ],
   "source": [
    "mmin_model = float(model.catalogue_cutoff_magnitude)\n",
    "print ('Minimum magnitude considered for the model is: ', mmin_model)\n",
    "mmax_obs = float(max(fcatal.data['magnitude']))\n",
    "print ('Maximum observed magnitude is: ', mmax_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the completeness table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/mpagani/Repos/model_building_tools/oqmbt/tests/tmp/project_test/completeness.hdf5\n",
      "\n",
      "The .hdf5 file does not contain completeness table for source 02\n",
      "Using the default completeness table set for the whole catalogue\n",
      "\n",
      "Completeness table:\n",
      "[[ 1973.       3.5 ]\n",
      " [ 1973.       3.75]\n",
      " [ 1973.       4.  ]\n",
      " [ 1973.       4.25]\n",
      " [ 1973.       4.5 ]\n",
      " [ 1967.       4.75]\n",
      " [ 1967.       5.  ]\n",
      " [ 1965.       5.25]\n",
      " [ 1965.       5.5 ]\n",
      " [ 1965.       5.75]\n",
      " [ 1913.       6.  ]\n",
      " [ 1913.       6.25]\n",
      " [ 1913.       6.5 ]\n",
      " [ 1913.       6.75]\n",
      " [ 1906.       7.  ]\n",
      " [ 1906.       7.25]]\n"
     ]
    }
   ],
   "source": [
    "compl_hdf5_filename = os.path.join(oqtkp.directory, oqtkp.compl_hdf5_filename)\n",
    "print ('Reading {:s}\\n'.format(compl_hdf5_filename))\n",
    "fhdf5 = h5py.File(compl_hdf5_filename,'r')\n",
    "\n",
    "grp = fhdf5[model_id]\n",
    "src_id = area_source_ids_list[0]\n",
    "if src_id in grp.keys():\n",
    "    compl_table = grp[src_id][()]\n",
    "    print ('Found completeness table for: <%s>' % (src_id))\n",
    "else:\n",
    "    print ('The .hdf5 file does not contain completeness table for source {:s}'.format(src_id))\n",
    "    if 'whole_catalogue' in grp.keys():\n",
    "        compl_table = grp['whole_catalogue'][()]\n",
    "        print ('Using the default completeness table set for the whole catalogue')\n",
    "    else:\n",
    "        print ('Default completeness table (whole catalogue) not defined')\n",
    "        raise ValueError()\n",
    "        compl_table = None\n",
    "print ('\\nCompleteness table:')\n",
    "print (compl_table)\n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double truncated magnitude-frequency distribution (MFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bval: nan (sigma=nan)\n",
      "aval: nan (sigma=nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpagani/Repos/oq-engine/openquake/hmtk/seismicity/occurrence/weichert.py:133: RuntimeWarning: overflow encountered in exp\n",
      "  beta_exp = np.exp(-beta * fmag)\n",
      "/Users/mpagani/Repos/oq-engine/openquake/hmtk/seismicity/occurrence/weichert.py:134: RuntimeWarning: overflow encountered in multiply\n",
      "  tjexp = tper * beta_exp\n",
      "/Users/mpagani/Repos/oq-engine/openquake/hmtk/seismicity/occurrence/weichert.py:140: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dldb = stmex / sumtex\n",
      "/Users/mpagani/Repos/oq-engine/openquake/hmtk/seismicity/occurrence/weichert.py:146: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  d2ldb2 = nkount * ((dldb ** 2.0) - (stm2x / sumtex))\n",
      "/Users/mpagani/Repos/oq-engine/openquake/hmtk/seismicity/occurrence/weichert.py:142: UserWarning: NaN occurs in Weichert iteration\n",
      "  warnings.warn('NaN occurs in Weichert iteration')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# selecting earthquakes\n",
    "idx = numpy.nonzero(compl_table[:,1] < numpy.max(fcatal.data['magnitude']))\n",
    "weichert_config = {'magnitude_interval': 0.1, \n",
    "                   'reference_magnitude': 0.0}\n",
    "weichert = Weichert()\n",
    "bval_wei, sigmab, aval_wei, sigmaa = weichert.calculate(fcatal, weichert_config, \n",
    "                                                        completeness=compl_table)\n",
    "#\n",
    "# info\n",
    "print ('bval: %.3f (sigma=%.3f)' % (bval_wei, sigmab))\n",
    "print ('aval: %.3f (sigma=%.3f)' % (aval_wei, sigmaa))\n",
    "#\n",
    "# computing seismicity rates\n",
    "cent_mag, t_per, n_obs = get_completeness_counts(fcatal, compl_table, binwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating /Users/mpagani/Repos/model_building_tools/oqmbt/tests/tmp/project_test/eqk_rates.hdf5\n",
      "    Group exists. Set group model01\n",
      "    Creating dataset 02\n"
     ]
    }
   ],
   "source": [
    "print('Updating', eqk_rates_hdf5_filename)\n",
    "fhdf5 = h5py.File(eqk_rates_hdf5_filename,'a')\n",
    "#\n",
    "# update/create group\n",
    "if model_id in fhdf5.keys():\n",
    "    print ('    Group exists. Set group %s' % (model_id))\n",
    "    grp = fhdf5[model_id]\n",
    "else:\n",
    "    print ('    Create group: %s' % (model_id))\n",
    "    grp = fhdf5.create_group(model_id)\n",
    "#\n",
    "# Update/create dataset\n",
    "rates = numpy.array([cent_mag, t_per, n_obs])\n",
    "if src_id in grp:\n",
    "    del grp[src_id]\n",
    "print('    Creating dataset %s' % (src_id))\n",
    "dataset = grp.create_dataset(src_id, data=rates)\n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "b-value nan must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d146c9da3de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_trunc_gr_model(aval_wei, bval_wei, mmin_model, mmax_obs, binwidth, catalogue=fcatal,\n\u001b[0;32m----> 2\u001b[0;31m         completeness=compl_table)\n\u001b[0m",
      "\u001b[0;32m/Users/mpagani/Repos/oq-engine/openquake/hmtk/plotting/seismicity/occurrence/recurrence_plot.py\u001b[0m in \u001b[0;36mplot_trunc_gr_model\u001b[0;34m(aval, bval, min_mag, max_mag, dmag, catalogue, completeness, figure_size, filename, filetype, dpi)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mPlots\u001b[0m \u001b[0ma\u001b[0m \u001b[0mGutenberg\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mRichter\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0minput_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedGRMFD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcatalogue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Plot only the modelled recurrence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mpagani/Repos/oq-engine/openquake/hazardlib/mfd/truncated_gr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, min_mag, max_mag, bin_width, a_val, b_val)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mpagani/Repos/oq-engine/openquake/hazardlib/mfd/truncated_gr.py\u001b[0m in \u001b[0;36mcheck_constraints\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b-value %g must be non-negative'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: b-value nan must be non-negative"
     ]
    }
   ],
   "source": [
    "plot_trunc_gr_model(aval_wei, bval_wei, mmin_model, mmax_obs, binwidth, catalogue=fcatal,\n",
    "        completeness=compl_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Update the project info\n",
    "c = Counter(fcatal.data['comment'])\n",
    "weights = {}\n",
    "annual_rate_source = []\n",
    "#\n",
    "# \n",
    "for srcid in area_source_ids_list:\n",
    "    #\n",
    "    # Computing weight\n",
    "    num_eqs_source = float(c['%s' % srcid])\n",
    "    weights[srcid] = num_eqs_source / fcatal.get_number_events()\n",
    "    print ('source', srcid, \\\n",
    "           ' | num. of eqks [eqks] %6.2f' % (c['%s' % srcid]), \\\n",
    "           ' | weight %s' % (weights[srcid]))\n",
    "    #\n",
    "    # attaching source to model \n",
    "    src = model.get_source(srcid) \n",
    "    src.a_gr=numpy.log10(10**aval_wei * weights[srcid])\n",
    "    src.b_gr=bval_wei\n",
    "#\n",
    "# saving the project\n",
    "oqtkp.save(log=True)\n",
    "#\n",
    "# check of the weight\n",
    "checkw = 0.0\n",
    "for key in weights:\n",
    "    checkw += weights[key]\n",
    "print ('check:', checkw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
