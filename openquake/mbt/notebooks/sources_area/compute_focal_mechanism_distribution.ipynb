{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute focal mechanism distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import h5py\n",
    "import numpy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from openquake.mbt.oqt_project import OQtProject\n",
    "from openquake.mbt.tools.geo import get_idx_points_inside_polygon\n",
    "from openquake.hmtk.parsers.catalogue.gcmt_ndk_parser import ParseNDKtoGCMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecclass(plungt, plungb, plungp):\n",
    "    \"\"\"\n",
    "    This is taken from the FMC package.\n",
    "    See https://josealvarezgomez.wordpress.com/\n",
    "\n",
    "    It provides a classification of the rupture mechanism based on the\n",
    "    Kaverina et al. (1996) methodology.\n",
    "\n",
    "    :parameter plungt:\n",
    "    :parameter plungb:\n",
    "    :parameter plungp:\n",
    "\n",
    "    \"\"\"\n",
    "    plunges = numpy.asarray((plungp, plungb, plungt))\n",
    "    P = plunges[0]\n",
    "    B = plunges[1]\n",
    "    T = plunges[2]\n",
    "    maxplung, axis = plunges.max(0), plunges.argmax(0)\n",
    "    if maxplung >= 67.5:\n",
    "        if axis == 0:  # P max\n",
    "            clase = 'N'  # normal faulting\n",
    "        elif axis == 1:  # B max\n",
    "            clase = 'SS'  # strike-slip faulting\n",
    "        elif axis == 2:  # T max\n",
    "            clase = 'R'  # reverse faulting\n",
    "    else:\n",
    "        if axis == 0:  # P max\n",
    "            if B > T:\n",
    "                clase = 'N-SS'  # normal - strike-slip faulting\n",
    "            else:\n",
    "                clase = 'N'  # normal faulting\n",
    "        if axis == 1:  # B max\n",
    "            if P > T:\n",
    "                clase = 'SS-N'  # strike-slip - normal faulting\n",
    "            else:\n",
    "                clase = 'SS-R'  # strike-slip - reverse faulting\n",
    "        if axis == 2:  # T max\n",
    "            if B > P:\n",
    "                clase = 'R-SS'  # reverse - strike-slip faulting\n",
    "            else:\n",
    "                clase = 'R'  # reverse faulting\n",
    "    return clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simpler(dct):\n",
    "    ndct = {'N': [], 'SS': [], 'R': []}\n",
    "    for key in dct.keys():\n",
    "        if key == 'SS-N' or key == 'SS-R':\n",
    "            ndct['SS'] += dct[key]\n",
    "        elif key == 'N-SS':\n",
    "            ndct['N'] += dct[key]\n",
    "        elif key == 'R-SS':\n",
    "            ndct['R'] += dct[key]\n",
    "        else:\n",
    "            ndct[key] += dct[key] \n",
    "    return ndct\n",
    "    \n",
    "def get_simplified_classification(histo, keys):\n",
    "    simpl_class = {'N': 0, 'SS': 0, 'R': 0}\n",
    "    for num, key in zip(histo, keys):\n",
    "        if key == 'SS-N' or key == 'SS-R':\n",
    "            simpl_class['SS'] += num\n",
    "        elif key == 'N-SS':\n",
    "            simpl_class['N'] += num\n",
    "        elif key == 'R-SS':\n",
    "            simpl_class['R'] += num\n",
    "        else:\n",
    "            simpl_class[key] += num \n",
    "    return simpl_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "#\n",
    "# read project\n",
    "project_pickle_filename = os.environ.get('OQMBT_PROJECT')\n",
    "oqtkp = OQtProject.load_from_file(project_pickle_filename)\n",
    "model_id = oqtkp.active_model_id\n",
    "model = oqtkp.models[model_id]\n",
    "prj_dir = os.path.dirname(project_pickle_filename)\n",
    "\n",
    "#\n",
    "# set hdf5 file names\n",
    "gcmt_filename = os.path.join(prj_dir, model.focal_mechanisms_filename)\n",
    "focal_mech_hdf5_filename = os.path.join(prj_dir, oqtkp.focal_mech_hdf5_filename)\n",
    "#\n",
    "# set source ID\n",
    "try:\n",
    "    area_source_ids_list = getattr(oqtkp,'active_source_id')\n",
    "except:\n",
    "    print('Active source ID not defined in the OQMBT project')\n",
    "    area_source_ids_list = ['10']\n",
    "#\n",
    "# info\n",
    "print('Active model is:', model_id)\n",
    "print('Processing area source with ID:', area_source_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create catalogue for the analysed area source\n",
    "### Read the focal mechanism catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# parsing the GCMT catalogue\n",
    "print(gcmt_filename)\n",
    "parser = ParseNDKtoGCMT(gcmt_filename)\n",
    "cat_gcmt = parser.read_file()\n",
    "#\n",
    "# area source information\n",
    "src_id = area_source_ids_list[0]\n",
    "src = model.sources[src_id]\n",
    "#\n",
    "# sheck if the area source has a geometry\n",
    "if 'polygon' in src.__dict__:\n",
    "    pass\n",
    "elif src_id in model.nrml_sources:\n",
    "    src.polygon = model.nrml_sources[src_id].polygon\n",
    "    src.name = model.nrml_sources[src_id].name\n",
    "    src.source_id = model.nrml_sources[src_id].source_id\n",
    "else: \n",
    "    print('The source does not have a geometry assigned')\n",
    "#\n",
    "# selecting earthquakes within the area source\n",
    "idxs = range(0, len(cat_gcmt.data['latitude']))\n",
    "tmp_idxs = get_idx_points_inside_polygon(cat_gcmt.data['longitude'], \n",
    "                                                 cat_gcmt.data['latitude'],\n",
    "                                                 src.polygon.lons, \n",
    "                                                 src.polygon.lats, \n",
    "                                                 idxs,\n",
    "                                                 0.0)\n",
    "print('The number of earthquakes within this polygon %d' % (len(tmp_idxs)))\n",
    "#\n",
    "# find the focal mechanisms located within the depth interval under investigation\n",
    "fidxs = []\n",
    "for idx in tmp_idxs:\n",
    "    if ((cat_gcmt.data['depth'][idx] < float(model.catalogue_maximum_depth)) &\n",
    "        (cat_gcmt.data['depth'][idx] > float(model.catalogue_minimum_depth))):\n",
    "        fidxs.append(idx)\n",
    "idxs_selected_fm = fidxs\n",
    "#\n",
    "# info\n",
    "print('The number of earthquakes within this polygon %d' % (len(tmp_idxs)))\n",
    "print('The number of selected earthquakes %d' % (len(idxs_selected_fm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the selected earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmclassification = {}\n",
    "eventfm = {}\n",
    "dip_1 = {}\n",
    "dip_2 = {}\n",
    "strike_1 = {}\n",
    "strike_2 = {}\n",
    "for idx in idxs_selected_fm:\n",
    "    plungeb = cat_gcmt.data['plunge_b'][idx]\n",
    "    plungep = cat_gcmt.data['plunge_p'][idx]\n",
    "    plunget = cat_gcmt.data['plunge_t'][idx]\n",
    "    mclass = mecclass(plunget, plungeb, plungep)\n",
    "    eventfm[idx] = mclass\n",
    "    if mclass in fmclassification:\n",
    "        fmclassification[mclass] += 1\n",
    "        dip_1[mclass].append(cat_gcmt.data['dip1'][idx])\n",
    "        dip_2[mclass].append(cat_gcmt.data['dip2'][idx])\n",
    "        strike_1[mclass].append(cat_gcmt.data['strike1'][idx])\n",
    "        strike_2[mclass].append(cat_gcmt.data['strike2'][idx])\n",
    "    else:\n",
    "        fmclassification[mclass] = 1\n",
    "        dip_1[mclass] = [cat_gcmt.data['dip1'][idx]]\n",
    "        dip_2[mclass] = [cat_gcmt.data['dip2'][idx]]\n",
    "        strike_1[mclass] = [cat_gcmt.data['strike1'][idx]]\n",
    "        strike_2[mclass] = [cat_gcmt.data['strike2'][idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal mechanisms histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['N', 'R', 'SS', 'N-SS', 'SS-N', 'SS-R', 'R-SS']\n",
    "\n",
    "bin_edges = numpy.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "histo = []\n",
    "\n",
    "for key in classes:\n",
    "    if key in fmclassification:\n",
    "        histo.append(fmclassification[key])\n",
    "    else:\n",
    "        histo.append(0)\n",
    "\n",
    "simplified = get_simplified_classification(histo, classes)\n",
    "print(fmclassification)\n",
    "print(simplified)\n",
    "\n",
    "histosimple = []\n",
    "for key in classes:\n",
    "    if key in simplified:\n",
    "        histosimple.append(simplified[key])\n",
    "    else:\n",
    "        histosimple.append(0)\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "plt.bar(bin_edges[0:-1], histo, \n",
    "        width=numpy.diff(bin_edges),\n",
    "        edgecolor='red', \n",
    "        facecolor='orange', \n",
    "        linewidth=3, \n",
    "        alpha=1.0,\n",
    "        label='Kaverina')\n",
    "\n",
    "plt.bar(bin_edges[0:-1], histosimple, \n",
    "        width=numpy.diff(bin_edges),\n",
    "        edgecolor='blue', \n",
    "        facecolor='None', \n",
    "        linewidth=3, \n",
    "        alpha=1.0,\n",
    "        label='Simplified')\n",
    "\n",
    "plt.ylabel(r'Earthquake count', fontsize=14)\n",
    "plt.grid(which='major', axis='y', linestyle='--')\n",
    "plt.title('Area source %s' % area_source_ids_list[0])\n",
    "\n",
    "be = numpy.array(bin_edges)\n",
    "plt.xticks(be[0:-1]+(be[1]-be[0])/2., classes)\n",
    "\n",
    "xlimits = plt.xlim([0, max(bin_edges)])\n",
    "leg = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strike Vs. Dip distribution for each rupture mechanism class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAVERINA = {'N'   : 'blue',\n",
    "            'SS'  : 'green',\n",
    "            'R'   : 'red',\n",
    "            'N-SS': 'turquoise',\n",
    "            'SS-N': 'palegreen',\n",
    "            'R-SS': 'goldenrod',\n",
    "            'SS-R': 'yellow' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "if len(fmclassification):\n",
    "    fs = 14\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(4, 2, wspace=0.0, hspace=0.0)\n",
    "    for key, igs in zip(classes, range(0, len(classes))):\n",
    "        ax = plt.subplot(gs[igs])\n",
    "        if key in strike_1:\n",
    "            plt.plot(strike_1[key], dip_1[key], 'o', markersize=8, color=KAVERINA[key])\n",
    "            plt.plot(strike_2[key], dip_2[key], 'o', markersize=6, color=KAVERINA[key], alpha=0.5, markeredgecolor='blue')\n",
    "        plt.xlim([0, 360])\n",
    "        plt.ylim([0, 90])\n",
    "        plt.grid(which='major', )\n",
    "\n",
    "        x = numpy.arange(30, 90, 30)\n",
    "        ax.set_yticks(x)\n",
    "        x = numpy.arange(30, 360, 30)\n",
    "        ax.set_xticks(x)\n",
    "        if igs in [0, 1, 2, 3, 4]:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xlabel('strike', fontsize=fs)\n",
    "        if igs in [1, 3, 5]:\n",
    "            ax.set_yticklabels([])\n",
    "        else:\n",
    "            ax.set_ylabel('dip', fontsize=fs)\n",
    "        plt.text(.05,.90,key,\n",
    "            horizontalalignment='left',\n",
    "            transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fmclassification):\n",
    "    stk1 = get_simpler(strike_1)\n",
    "    stk2 = get_simpler(strike_2)\n",
    "    dip1 = get_simpler(dip_1)\n",
    "    dip2 = get_simpler(dip_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fmclassification):\n",
    "    fs = 14\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    gs = gridspec.GridSpec(3, 1, wspace=0.0, hspace=0.0)\n",
    "    for key, igs in zip(dip1.keys(), range(0, len(dip1.keys()))):\n",
    "        ax = plt.subplot(gs[igs])\n",
    "        if key in dip1.keys():\n",
    "            plt.plot(stk1[key], dip1[key], 'o', markersize=8, color=KAVERINA[key])\n",
    "            plt.plot(stk2[key], dip2[key], 'o', markersize=6, color=KAVERINA[key], alpha=0.5, markeredgecolor='blue')\n",
    "        plt.xlim([0, 360])\n",
    "        plt.ylim([0, 90])\n",
    "        plt.grid(which='major', )\n",
    "\n",
    "        x = numpy.arange(30, 90, 30)\n",
    "        ax.set_yticks(x)\n",
    "        x = numpy.arange(30, 360, 30)\n",
    "        ax.set_xticks(x)\n",
    "        if igs in [0, 1]:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xlabel('strike', fontsize=fs)\n",
    "        ax.set_ylabel('dip', fontsize=fs)\n",
    "        plt.text(.05,.90,key,\n",
    "            horizontalalignment='left',\n",
    "            transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot focal mechanisms map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fmclassification) and plot:\n",
    "    import cartopy\n",
    "    import cartopy.crs as ccrs\n",
    "    import matplotlib.patheffects as PathEffects\n",
    "    from obspy.imaging.beachball import beach\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10), dpi=300)\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), \n",
    "                      draw_labels=True,\n",
    "                      linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = False\n",
    "\n",
    "    dlt = 2\n",
    "    limits = [min(src.polygon.lons)-dlt, min(src.polygon.lats)-dlt, \n",
    "              max(src.polygon.lons)+dlt, max(src.polygon.lats)+dlt]\n",
    "    tmp = ax.coastlines()\n",
    "    #ax.add_feature(cartopy.feature.OCEAN, zorder=0)\n",
    "    # set the area for the plot\n",
    "    tmp = ax.set_extent([limits[0], limits[2], limits[1], limits[3]], ccrs.Geodetic())\n",
    "\n",
    "    # catalogue\n",
    "    ax.plot(cat_gcmt.data['longitude'], cat_gcmt.data['latitude'], 's',\n",
    "            linewidth=1, alpha=0.4, transform=ccrs.Geodetic(), color='green',\n",
    "            path_effects=[PathEffects.withStroke(linewidth=3, foreground=\"g\")]) \n",
    "    ax.plot(src.polygon.lons, src.polygon.lats, '-', linewidth=3, color='blue', transform=ccrs.Geodetic())\n",
    "    ax.plot(cat_gcmt.data['longitude'][idxs_selected_fm], \n",
    "            cat_gcmt.data['latitude'][idxs_selected_fm], 'o', linewidth=3, color='blue', transform=ccrs.Geodetic())\n",
    "\n",
    "    # \n",
    "    for idx, lon, lat, mag in zip(idxs_selected_fm,\n",
    "                                    cat_gcmt.data['longitude'][idxs_selected_fm],\n",
    "                                    cat_gcmt.data['latitude'][idxs_selected_fm],\n",
    "                                    cat_gcmt.data['magnitude'][idxs_selected_fm]):\n",
    "\n",
    "        eve = cat_gcmt.gcmts[idx]\n",
    "        com = eve.moment_tensor._to_6component()\n",
    "        try: \n",
    "            bcc = beach(com, xy=(lon, lat), \n",
    "                        width=eve.magnitude*0.1,\n",
    "                        linewidth=1, \n",
    "                        zorder=20, \n",
    "                        size=mag,\n",
    "                        facecolor=KAVERINA[eventfm[idx]])\n",
    "            bcc.set_alpha(0.8)\n",
    "            bcc.set_label(eventfm[idx])\n",
    "            ax.add_collection(bcc)\n",
    "        except:\n",
    "            print('Error in the moment tensor?', com)\n",
    "            continue\n",
    "    #\n",
    "    for lab in classes:\n",
    "        circ1 = plt.plot(limits[0]-0.1, \n",
    "                         limits[1]-0.1, \n",
    "                         linestyle=\"none\", \n",
    "                         marker=\"o\", \n",
    "                         alpha=1.0, \n",
    "                         markersize=10.0, \n",
    "                         markerfacecolor=KAVERINA[lab], \n",
    "                         label=lab)\n",
    "    # Legend\n",
    "    leg = plt.legend()\n",
    "    # Grid\n",
    "    grd = ax.gridlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fmclassification):\n",
    "    #\n",
    "    # set the csv file name\n",
    "    aa = re.sub('\\.hdf5', '', os.path.basename(focal_mech_hdf5_filename))\n",
    "    csv_filename = '{:s}-{:s}-{:s}.csv'.format(aa, model_id, src_id)\n",
    "    print(csv_filename)\n",
    "    #\n",
    "    #\n",
    "    path = os.path.join(oqtkp.directory, 'focal_mechs')\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print ('Creating folder: {:s}'.format(path))\n",
    "    else:\n",
    "        print ('Folder {:s} exists'.format(path))\n",
    "    #\n",
    "    # Writing csv file\n",
    "    outfile = os.path.join(path, csv_filename)\n",
    "    print ('Writing {:s}'.format(outfile))\n",
    "    fou = open(outfile, 'w')\n",
    "    fou.write('strike,dip,rake,weight\\n')\n",
    "    fou.write('{:.2f},{:.2f},{:.2f},{:.2f}\\n'.format(0, 90, 0, 1.0))\n",
    "    fou.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 files\n",
    "### Updating the hdf5 file with focal mechanisms data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fmclassification):\n",
    "    print('Writing', focal_mech_hdf5_filename)\n",
    "    fhdf5 = h5py.File(focal_mech_hdf5_filename,'a')\n",
    "    src_id = area_source_ids_list[0]\n",
    "\n",
    "    # Update/create model group\n",
    "    if model_id in fhdf5.keys():\n",
    "        print('Group exists. Set group %s' % (model_id))\n",
    "        grp = fhdf5[model_id]\n",
    "    else:\n",
    "        print('Create group: %s' % (model_id))\n",
    "        grp = fhdf5.create_group(model_id)\n",
    "\n",
    "    # Update/create source group\n",
    "    if src_id in fhdf5[model_id].keys():\n",
    "        print('Group exists. Set group %s' % (src_id))\n",
    "        grpsrc = fhdf5[model_id][src_id]\n",
    "    else:\n",
    "        print('Create group: %s' % (src_id))\n",
    "        grpsrc = fhdf5[model_id].create_group(src_id)\n",
    "\n",
    "    # Update/create datasets\n",
    "    dset_ids = ['kaverina_histogram', 'simplified_histogram']\n",
    "    for dset_id in dset_ids:\n",
    "        if dset_id in grpsrc:\n",
    "            del grpsrc[dset_id]\n",
    "\n",
    "    dataset = grpsrc.create_dataset('kaverina_histogram', data=histo)\n",
    "    dataset.attrs['labels'] = '-'.join(['%s' % lab for lab in classes])\n",
    "    dataset = grpsrc.create_dataset('simplified_histogram', data=histosimple)\n",
    "    dataset.attrs['labels'] = '-'.join(['%s' % lab for lab in classes])\n",
    "\n",
    "    strike_simpl_1 = stk1\n",
    "    strike_simpl_2 = stk1\n",
    "    dip_simpl_1 = dip1\n",
    "    dip_simpl_2 = dip2\n",
    "\n",
    "    for tpe in ['strike_1', 'strike_2', 'dip_1', 'dip_2',\n",
    "               'strike_simpl_1', 'strike_simpl_2', 'dip_simpl_1', 'dip_simpl_2']:\n",
    "\n",
    "        # Update/create source group\n",
    "        if tpe in fhdf5[model_id][src_id].keys():\n",
    "            print('Group exists. Set group %s' % (tpe))\n",
    "            grpsrc = fhdf5[model_id][src_id][tpe]\n",
    "            # cleaning\n",
    "            for dset_id in grpsrc:\n",
    "                del grpsrc[dset_id]   \n",
    "        else:\n",
    "            print('Create group: %s' % (tpe))\n",
    "            grpsrc = fhdf5[model_id][src_id].create_group(tpe)\n",
    "\n",
    "        tdct = eval(tpe)\n",
    "        for key in tdct.keys():\n",
    "            dataset = grpsrc.create_dataset(key, data=tdct[key])\n",
    "\n",
    "    fhdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the hdf5 containing the nodal plane distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fmclassification):\n",
    "    #\n",
    "    # open the hdf5 containing the nodal plane information\n",
    "    nodal_plane_dist_filename = os.path.join(oqtkp.directory, model.nodal_plane_dist_filename)\n",
    "    fhdf5 = h5py.File(nodal_plane_dist_filename,'a')\n",
    "    #\n",
    "    # add the dataset for the current area source, if missing\n",
    "    if src_id in fhdf5.keys():\n",
    "        print ('Datasets already available')\n",
    "    else:\n",
    "        print ('Adding dummy dataset')\n",
    "        x = numpy.zeros(1, dtype=[('strike','f4'),('dip', 'f4'), ('rake', 'f4'), ('wei', 'f4')])\n",
    "        dset = fhdf5.create_dataset(src_id, data=x)\n",
    "    fhdf5.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
